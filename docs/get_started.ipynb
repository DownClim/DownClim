{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started with DownClim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DownClim` is a simple and easy to use Python package for performing a climate downscaling on future climatic projections. Based on a reference product, and a set of projections from [CMIP6](https://pcmdi.llnl.gov/CMIP6/) and [CORDEX](https://cordex.org/) simulations, `DownClim` will help you to generate a climate projection for your region of interest.\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `DownClimContext` object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from downclim.downclim import DownClimContext, define_DownClimContext_from_file, generate_DownClimContext_template_file\n",
    "from downclim.dataset.cmip6 import CMIP6Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DownClimContext` object is the main object of the `DownClim` package. It contains all the relevant information necessary to perform your downscaling on your area of interest. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check directly the documentation of the `DownClimContext` object to have an extensive overview of how to define it properly. In the following section, we will see the main fields included in the `DownClimContext` object to perform a downscaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main fields of the `DownClimContext` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DownClimContext` objects contain multiple attributes. The most relevant ones are:\n",
    "\n",
    "- `aois`: the areas of interest. You can define one or multiple areas of interest, and you have the possibility to define them either as a `str`, a `geopandas.GeoDataFrame` or a simple Python `tuple` of coordinates.\n",
    "    - `str`: the name provided must be recognized by [GADM](https://gadm.org/) to retrieve the corresponding shapefile.\n",
    "    - `geopandas.GeoDataFrame` containing the directly shapefile of the area of interest.\n",
    "    - `tuple` of coordinates `(lon_min, lon_max, lat_min, lat_max, str)` where the last `str` is the name of the area of interest.\n",
    "  \n",
    "- `variables`: the variables to downscale. You want to select the climate variables that you want to downscale in your future climate. You must provide them as a list of strings, and the name of the variables have to match the `CMIP6` / `CORDEX` naming convention (see [CMIP6 CMOR Tables](https://github.com/PCMDI/cmip6-cmor-tables)). For example, you can select the following variables: `['tas', 'pr']` for 2m temperature and precipitation. Please note that the variables selected must be available both in the climate simulations and in the reference product.\n",
    "\n",
    "- `baseline_product`: the reference product used for downscaling. \n",
    "\n",
    "- `downscaling_methods`: the downscaling method to use. To downscale your climate data on your area of interest, you might want to use different downscaling methods. So far, `DownClim` only supports the `bias_correction` method, but other methods can be easily adopted and will be available soon.\n",
    "\n",
    "- `use_cmip6` & `use_cordex`: whether to use CMIP6 or CORDEX simulations. You can select the climate simulation you want to use for your future projections. `CMIP6` projections are available for a large number of models and scenarios, at global scale and usually at a coarse resolution. `CORDEX` simulations are regional projections, much less numerous but at a finer resolution.\n",
    "\n",
    "- `baseline_periods`, `evaluation_periods`, `projection_periods`: the years to use for the baseline, evaluation and projection periods. To perform a downscaling, you must define the baseline period, evaluation period and projection period. \n",
    "  - The baseline period is the period used to calibrate the downscaling method. It is a historical period that must overlap the reference product and the historical climate simulations.\n",
    "  - The evaluation period is the period that overlaps the reference product and the future climate simulations. It is used to evaluate the calibration of the downscaling method performed on the baseline period. \n",
    "  - The projection period is the period for which you want to generate the future climate projections downscaled.\n",
    "\n",
    "\n",
    "You can create a `DownClimContext` object either directly, or by defining a configuration file in a `.yaml` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DownClimContext` object creation directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can instantiate a `DownClimContext` object directly by providing the necessary information either via the constructor or providing a dictionary filled with the required keys. Not all fields are mandatory, and default values are used for the omitted fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownClimContext_example = DownClimContext(\n",
    "    aoi=\"Vanuatu\",\n",
    "    variable=[\"tas\", \"pr\"],\n",
    "    historical_period=(1980, 1981),\n",
    "    evaluation_period=(2017, 2018),\n",
    "    projection_period=(2099, 2100),\n",
    "    use_cordex=False,\n",
    "    use_cmip6=True,\n",
    "    cmip6_context=CMIP6Context()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DownClimContext` object creation from a `.yaml` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also define a `DownClimContext` object from a `.yaml` file. You must first create a template `.yaml` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_DownClimContext_template_file(output_file = './DownClimContext_example.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after filling the sections of the file, your `DownClim` configuration file should look like this:\n",
    "\n",
    "```yaml\n",
    "##\n",
    "## All fields except aoi have default values. If the field is not specified, the default value is used.\n",
    "####################################################\n",
    "# aoi\n",
    "aoi: \"Vanuatu\"\n",
    "\n",
    "# variables\n",
    "variable: [\"tas\", \"tasmin\", \"tasmax\", \"pr\"]\n",
    "time_frequency: \"mon\"\n",
    "\n",
    "# downscaling\n",
    "downscaling_aggregation: \"monthly-mean\"\n",
    "downscaling_method: \"bias_correction\"\n",
    "\n",
    "# data and simulations\n",
    "baseline_product: \"chelsa2\"\n",
    "use_cordex: false\n",
    "use_cmip6: true\n",
    "cordex_context: {}\n",
    "cmip6_context: {}\n",
    "baseline_period: [1980, 2005]\n",
    "evaluation_period: [2006, 2019]\n",
    "projection_period: [2071, 2100]\n",
    "evaluation_product: [\"chirps\", \"chelsa2\"]\n",
    "\n",
    "# internal computation\n",
    "nb_threads: 2\n",
    "memory_mb: 4096\n",
    "chunks: {\"time\": 1, \"lat\": 1000, \"lon\": 1000}\n",
    "\n",
    "# directories\n",
    "output_dir: \"results\"\n",
    "tmp_dir: \"tmp\"\n",
    "keep_tmp_dir: \"False\"\n",
    "\n",
    "# data access\n",
    "esgf_credential: \"../config/esgf_credential.yaml\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arsouze/Documents/Modeles/Codes/DownClim/src/downclim/downclim.py:373: UserWarning: Directory tmp did not exist and was created.\n",
      "  logger.warning(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aoi': [                                            geometry GID_0   NAME_0\n",
       "  0  MULTIPOLYGON (((169.7766 -20.2488, 169.7719 -2...   VUT  Vanuatu],\n",
       " 'variable': ['tas', 'tasmin', 'tasmax', 'pr'],\n",
       " 'time_frequency': <Frequency.MONTHLY: 'monthly'>,\n",
       " 'downscaling_aggregation': <Aggregation.MONTHLY_MEAN: 'monthly-mean'>,\n",
       " 'baseline_product': <DataProduct.CHELSA: product_name='chelsa', period=(1979, 2018), scale_factor={'pr': 0.1, 'tas': 0.1, 'tasmin': 0.1, 'tasmax': 0.1}, add_offset={'pr': 0, 'tas': -273.15, 'tasmin': -273.15, 'tasmax': -273.15}, lon_lat_names={'lon': 'x', 'lat': 'y'}, url='https://os.zhdk.cloud.switch.ch/chelsav2/GLOBAL'>,\n",
       " 'evaluation_product': [<DataProduct.CHIRPS: product_name='chirps', period=(1980, 2024), scale_factor={'pr': 1}, add_offset={'pr': 0}, lon_lat_names={'lon': 'lon', 'lat': 'lat'}, url='UCSB-CHG/CHIRPS/DAILY'>,\n",
       "  <DataProduct.CHELSA: product_name='chelsa', period=(1979, 2018), scale_factor={'pr': 0.1, 'tas': 0.1, 'tasmin': 0.1, 'tasmax': 0.1}, add_offset={'pr': 0, 'tas': -273.15, 'tasmin': -273.15, 'tasmax': -273.15}, lon_lat_names={'lon': 'x', 'lat': 'y'}, url='https://os.zhdk.cloud.switch.ch/chelsav2/GLOBAL'>],\n",
       " 'downscaling_method': <DownscaleMethod.BIAS_CORRECTION: 'bias_correction'>,\n",
       " 'use_cordex': False,\n",
       " 'use_cmip6': True,\n",
       " 'cordex_context': {'project': ['CORDEX'],\n",
       "  'product': ['output'],\n",
       "  'domain': None,\n",
       "  'institute': None,\n",
       "  'driving_model': None,\n",
       "  'experiment': ['historical', 'rcp26'],\n",
       "  'experiment_family': None,\n",
       "  'ensemble': ['r1i1p1'],\n",
       "  'rcm_name': None,\n",
       "  'rcm_version': None,\n",
       "  'frequency': <Frequency.MONTHLY: 'monthly'>,\n",
       "  'variable': ['tas', 'pr'],\n",
       "  'variable_long_name': None},\n",
       " 'cmip6_context': {'project': ['ScenarioMIP', 'CMIP'],\n",
       "  'institute': None,\n",
       "  'source': None,\n",
       "  'experiment': ['ssp245', 'historical'],\n",
       "  'ensemble': ['r1i1p1f1'],\n",
       "  'frequency': <Frequency.MONTHLY: 'monthly'>,\n",
       "  'variable': ['tas', 'pr'],\n",
       "  'grid_label': None},\n",
       " 'baseline_period': (1980, 1981),\n",
       " 'evaluation_period': (2017, 2018),\n",
       " 'projection_period': (2099, 2100),\n",
       " 'nb_threads': 2,\n",
       " 'memory_mb': 4096,\n",
       " 'chunks': {'time': 1, 'lat': 1000, 'lon': 1000},\n",
       " 'output_dir': 'results',\n",
       " 'tmp_dir': 'tmp',\n",
       " 'keep_tmp_dir': False,\n",
       " 'cmip6_simulations_to_downscale': None,\n",
       " 'cordex_simulations_to_downscale': None,\n",
       " 'esgf_credentials': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DownClimContext_example = define_DownClimContext_from_file('./DownClimContext_example.yaml')\n",
    "DownClimContext_example.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download required data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your `DownClimContext` object is defined correctly, you can download the required data defined in the context. You can do it by using the `download_data` method of the `DownClimContext` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CHELSA data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting year \"1980\" for variables \"tas\" and areas of interest : \"['Vanuatu']\"Getting year \"1981\" for variables \"tas\" and areas of interest : \"['Vanuatu']\"\n",
      "\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tas_1980.nc\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tas_1981.nc\n",
      "Getting year \"1980\" for variables \"tasmin\" and areas of interest : \"['Vanuatu']\"\n",
      "Getting year \"1981\" for variables \"tasmin\" and areas of interest : \"['Vanuatu']\"\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tasmin_1980.nc\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tasmin_1981.nc\n",
      "Getting year \"1980\" for variables \"tasmax\" and areas of interest : \"['Vanuatu']\"Getting year \"1981\" for variables \"tasmax\" and areas of interest : \"['Vanuatu']\"\n",
      "\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tasmax_1980.nc\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_tasmax_1981.nc\n",
      "Getting year \"1980\" for variables \"pr\" and areas of interest : \"['Vanuatu']\"\n",
      "Getting year \"1981\" for variables \"pr\" and areas of interest : \"['Vanuatu']\"\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "Concatenating data for area of interest : Vanuatu\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_pr_1981.nc\n",
      "saving file tmp/chelsa/chelsa_Vanuatu_pr_1980.nc\n",
      "Merging files by aoi...\n",
      "Merging files for area Vanuatu...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: Not a valid ID",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/backends/api.py:1662\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m combine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[0;32m-> 1662\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/core/combine.py:983\u001b[0m, in \u001b[0;36mcombine_by_coords\u001b[0;34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[0;32m--> 983\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrouped_by_vars\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    997\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    998\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m   1002\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/core/combine.py:984\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[1;32m    983\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 984\u001b[0m         \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    997\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    998\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m   1002\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/core/combine.py:645\u001b[0m, in \u001b[0;36m_combine_single_variable_hypercube\u001b[0;34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one Dataset is required to resolve variable names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor combined hypercube.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m     )\n\u001b[0;32m--> 645\u001b[0m combined_ids, concat_dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_concat_order_from_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# check that datasets form complete hypercube\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/core/combine.py:158\u001b[0m, in \u001b[0;36m_infer_concat_order_from_coords\u001b[0;34m(datasets)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(datasets) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m concat_dims:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any dimension coordinates to use to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder the datasets for concatenation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m combined_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tile_ids, datasets, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find any dimension coordinates to use to order the datasets for concatenation",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDownClimContext_example\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Modeles/Codes/DownClim/src/downclim/downclim.py:558\u001b[0m, in \u001b[0;36mDownClimContext.download_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting data download...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    557\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Downloading baseline product...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_baseline_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Downloading evaluation product...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_evaluation_product()\n",
      "File \u001b[0;32m~/Documents/Modeles/Codes/DownClim/src/downclim/downclim.py:421\u001b[0m, in \u001b[0;36mDownClimContext._get_baseline_product\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading baseline product...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline_product \u001b[38;5;129;01mis\u001b[39;00m DataProduct\u001b[38;5;241m.\u001b[39mCHELSA:\n\u001b[0;32m--> 421\u001b[0m     \u001b[43mget_chelsa2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43maoi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maoi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseline_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownscaling_aggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnb_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseline_product\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseline_product\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_tmp_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_tmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline_product \u001b[38;5;129;01mis\u001b[39;00m DataProduct\u001b[38;5;241m.\u001b[39mCHIRPS:\n\u001b[1;32m    433\u001b[0m     get_chirps(\n\u001b[1;32m    434\u001b[0m         aoi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maoi,\n\u001b[1;32m    435\u001b[0m         period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline_period,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline_product\u001b[38;5;241m.\u001b[39mproduct_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    439\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Modeles/Codes/DownClim/src/downclim/dataset/chelsa2.py:256\u001b[0m, in \u001b[0;36mget_chelsa2\u001b[0;34m(aoi, variable, period, frequency, aggregation, nb_threads, output_dir, tmp_dir, keep_tmp_dir)\u001b[0m\n\u001b[1;32m    254\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m climatology_filename(output_dir, aoi_n, data_product, aggregation, period)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerging files for area \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m aoi_n \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m ds_aoi_period \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths2\u001b[49m\u001b[43m[\u001b[49m\u001b[43maoi_n\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m dmin, dmax \u001b[38;5;241m=\u001b[39m split_period(period)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;241m==\u001b[39m Aggregation\u001b[38;5;241m.\u001b[39mMONTHLY_MEAN:\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/backends/api.py:1677\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m-> 1677\u001b[0m         \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m combined\u001b[38;5;241m.\u001b[39mset_close(partial(_multi_file_closer, closers))\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/core/common.py:1257\u001b[0m, in \u001b[0;36mDataWithCoords.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Release any resources linked to this object.\"\"\"\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/backends/netCDF4_.py:597\u001b[0m, in \u001b[0;36mNetCDF4DataStore.close\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/downclim/lib/python3.13/site-packages/xarray/backends/file_manager.py:234\u001b[0m, in \u001b[0;36mCachingFileManager.close\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    232\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, default)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2669\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.close\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2636\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset._close\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2164\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: Not a valid ID"
     ]
    }
   ],
   "source": [
    "DownClimContext_example.download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a downscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your `DownClimContext` object is defined correctly and your data downloaded, you can directly perform a downscaling according to the context.\n",
    "\n",
    "It gets as simple as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2063765836.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from downclim.\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DownClimContext_example.downscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downclim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
